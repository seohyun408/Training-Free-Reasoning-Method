
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Thought Anchor & Contrastive Generation - Methodology</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 3px solid #667eea;
            padding-bottom: 15px;
            margin-bottom: 30px;
        }
        h2 {
            color: #667eea;
            margin-top: 40px;
            margin-bottom: 20px;
            border-left: 5px solid #667eea;
            padding-left: 15px;
        }
        h3 {
            color: #555;
            margin-top: 30px;
            margin-bottom: 15px;
        }
        .section {
            margin-bottom: 40px;
        }
        .formula {
            background: #f9f9f9;
            padding: 15px;
            border-left: 4px solid #667eea;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }
        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 14px;
        }
        .algorithm-box {
            background: #e8f5e9;
            padding: 20px;
            border-left: 5px solid #4caf50;
            margin: 20px 0;
            border-radius: 5px;
        }
        .model-info {
            background: #e3f2fd;
            padding: 20px;
            border-left: 5px solid #2196f3;
            margin: 20px 0;
            border-radius: 5px;
        }
        .key-point {
            background: #fff3e0;
            padding: 15px;
            border-left: 5px solid #ff9800;
            margin: 15px 0;
            border-radius: 5px;
        }
        ul, ol {
            margin: 15px 0;
            padding-left: 25px;
        }
        li {
            margin: 8px 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th {
            background: #667eea;
            color: white;
            padding: 12px;
            text-align: left;
        }
        td {
            padding: 10px;
            border-bottom: 1px solid #ddd;
        }
        tr:hover {
            background: #f5f5f5;
        }
        .toc {
            background: #f0f4ff;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
        }
        .toc a {
            text-decoration: none;
            color: #667eea;
        }
        .toc a:hover {
            text-decoration: underline;
        }
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üìö Thought Anchor & Contrastive Generation Methodology</h1>

        <div class="toc">
            <h3>Table of Contents</h3>
            <ol>
                <li><a href="#overview">Overview</a></li>
                <li><a href="#model">Model Architecture</a></li>
                <li><a href="#stage1">Stage 1: Thought Anchor Detection</a></li>
                <li><a href="#stage2">Stage 2: Contrastive Generation</a></li>
                <li><a href="#stage3">Stage 3: PCA Context Vector</a></li>
                <li><a href="#implementation">Implementation Details</a></li>
                <li><a href="#code">Key Code Snippets</a></li>
            </ol>
        </div>

        <div id="overview" class="section">
            <h2>1. Overview</h2>
            <p>
                This project implements a three-stage approach for analyzing and improving reasoning in
                Vision-Language Models (VLMs) using:
            </p>
            <ul>
                <li><strong>Thought Anchor Detection</strong>: Identifying critical reasoning steps using KL divergence</li>
                <li><strong>Contrastive Generation</strong>: Generating positive/negative continuations from anchor points</li>
                <li><strong>PCA Context Vectors</strong>: Extracting directional guidance from contrastive pairs</li>
            </ul>

            <div class="key-point">
                <strong>Key Innovation:</strong> We use attention masking to suppress sentence representations and
                measure their impact via KL divergence, identifying "thought anchors" - critical sentences that
                most influence subsequent reasoning.
            </div>
        </div>

        <div id="model" class="section">
            <h2>2. Model Architecture</h2>

            <div class="model-info">
                <h3>Qwen3-VL-8B-Instruct</h3>
                <table>
                    <tr>
                        <th>Property</th>
                        <th>Value</th>
                    </tr>
                    <tr>
                        <td>Model Name</td>
                        <td><code>Qwen/Qwen3-VL-8B-Instruct</code></td>
                    </tr>
                    <tr>
                        <td>Architecture</td>
                        <td>Transformer-based Vision-Language Model</td>
                    </tr>
                    <tr>
                        <td>Parameters</td>
                        <td>~8 Billion</td>
                    </tr>
                    <tr>
                        <td>Precision</td>
                        <td>float16</td>
                    </tr>
                    <tr>
                        <td>Context Length</td>
                        <td>Supports multimodal inputs (image + text)</td>
                    </tr>
                </table>
            </div>

            <h3>2.1 Generation Configuration</h3>
            <div class="code-block">
# Reasoning Generation
max_new_tokens = 256
do_sample = False  # Greedy decoding for reasoning
temperature = 0.7

# Contrastive Sampling
num_samples = 5
do_sample = True
temperature = 0.9
top_p = 0.95
            </div>
        </div>

        <div id="stage1" class="section">
            <h2>3. Stage 1: Thought Anchor Detection</h2>

            <h3>3.1 Sentence Chunking</h3>
            <p>
                Split reasoning text into sentences based on numbered patterns (1., 2., 3., ...) or sentence boundaries.
            </p>

            <div class="formula">
Chunks = [s‚ÇÅ, s‚ÇÇ, s‚ÇÉ, ..., s‚Çô]
where s·µ¢ represents the i-th reasoning step
            </div>

            <h3>3.2 Attention Masking Strategy (Method 3)</h3>
            <p>
                For each sentence s‚±º, we suppress its representation by masking attention weights:
            </p>

            <div class="formula">
Let attn_mask[i, j] represent attention from position i to position j

Suppression of sentence j:
    attn_mask[all_positions, token_range(s‚±º)] = -inf

This prevents all tokens from attending to sentence s‚±º,
effectively removing its contribution to subsequent reasoning.
            </div>

            <h3>3.3 KL Divergence Computation</h3>
            <p>
                We measure how much suppressing sentence s‚±º affects the distribution at sentence s·µ¢:
            </p>

            <div class="formula">
KL(i, j) = D_KL(P_original(s·µ¢) || P_suppressed_j(s·µ¢))

where:
    P_original(s·µ¢) = original distribution at sentence s·µ¢
    P_suppressed_j(s·µ¢) = distribution at s·µ¢ when s‚±º is suppressed

D_KL(P || Q) = Œ£ P(x) log(P(x) / Q(x))
            </div>

            <div class="algorithm-box">
                <h4>Algorithm: KL Matrix Computation</h4>
<pre>
for j in range(num_sentences):
    # Get normal outputs
    logits_orig = model.forward(input_ids)
    P_orig = softmax(logits_orig)

    # Suppress sentence j using attention mask
    attention_mask_suppressed = create_suppression_mask(j)
    logits_supp = model.forward(input_ids, attention_mask=attention_mask_suppressed)
    P_supp = softmax(logits_supp)

    # Compute KL divergence for each sentence i
    for i in range(num_sentences):
        if i > j:  # Only compute for future sentences
            KL[i, j] = sum(P_orig[i] * log(P_orig[i] / P_supp[i]))
</pre>
            </div>

            <h3>3.4 Anchor Vector Extraction</h3>
            <p>
                We aggregate KL divergences to compute importance scores:
            </p>

            <div class="formula">
Anchor Score (Outgoing Method):

anchor_vector[j] = mean(KL[i, j] for i > j)

Interpretation:
    High score ‚Üí sentence s‚±º significantly influences future reasoning
    Low score ‚Üí sentence s‚±º has minimal impact on subsequent steps
            </div>

            <div class="code-block">
def compute_anchor_vector(kl_matrix, method="outgoing"):
    # Extract anchor importance scores from KL matrix
    #
    # Args:
    #     kl_matrix: [N, N] where kl_matrix[i, j] = KL divergence
    #                at position i when suppressing j
    #     method: "outgoing" | "incoming" | "combined"
    #
    # Returns:
    #     anchor_vector: [N] importance scores

    num_sentences = kl_matrix.shape[0]
    anchor_vector = np.zeros(num_sentences)

    if method == "outgoing":
        for i in range(num_sentences):
            future_effects = kl_matrix[i+1:, i]
            anchor_vector[i] = np.mean(future_effects) if len(future_effects) > 0 else 0.0

    return anchor_vector
            </div>
        </div>

        <div id="stage2" class="section">
            <h2>4. Stage 2: Contrastive Generation</h2>

            <h3>4.1 Anchor Selection</h3>
            <p>
                Select the sentence with highest anchor score (excluding the final answer):
            </p>

            <div class="formula">
anchor_idx = argmax(anchor_vector[:-1])
prefix = concatenate(s‚ÇÅ, s‚ÇÇ, ..., s_anchor_idx)
            </div>

            <h3>4.2 Multiple Continuations</h3>
            <p>
                Generate N=5 different continuations from the anchor point using sampling:
            </p>

            <div class="code-block">
for i in range(5):
    continuation_i = model.generate(
        prefix_text,
        do_sample=True,
        temperature=0.9,
        top_p=0.95,
        max_new_tokens=128
    )
            </div>

            <h3>4.3 Probability Scoring</h3>
            <p>
                For each continuation, compute a score based on whether it leads to the correct answer:
            </p>

            <div class="formula">
Score Function:

1. Extract final answer from continuation: answer_i = extract_final_answer(continuation_i)

2. Compute fluency (average token probability):
   fluency_i = exp(mean(log P(token_k) for k in continuation_i))

3. Final score:
   score_i = {
       fluency_i           if answer_i == correct_answer
       fluency_i √ó 0.01    otherwise
   }

This heavily penalizes incorrect answers while preserving
continuous probability values for correct ones.
            </div>

            <div class="algorithm-box">
                <h4>Algorithm: Fluency Calculation</h4>
<pre>
def compute_fluency(model, prefix, continuation):
    # Tokenize full sequence
    full_text = prefix + continuation
    full_tokens = tokenizer(full_text)
    prefix_tokens = tokenizer(prefix)
    prefix_len = len(prefix_tokens)

    # Forward pass to get logits
    with torch.no_grad():
        outputs = model(full_tokens, return_dict=True)
        logits = outputs.logits  # (seq_len, vocab_size)

    # Calculate average log-probability of continuation tokens
    total_log_prob = 0
    count = 0

    for i in range(prefix_len, len(full_tokens)):
        token_logits = logits[i-1]  # Predict token i from position i-1
        probs = softmax(token_logits)
        actual_token = full_tokens[i]
        prob = probs[actual_token]

        total_log_prob += log(prob)
        count += 1

    # Geometric mean
    fluency = exp(total_log_prob / count)
    return fluency
</pre>
            </div>

            <h3>4.4 Positive/Negative Selection</h3>
            <div class="formula">
Positive sample: continuation with highest score
Negative sample: continuation with lowest score

positive_idx = argmax(score_i for i in 1..5)
negative_idx = argmin(score_i for i in 1..5)
            </div>
        </div>

        <div id="stage3" class="section">
            <h2>5. Stage 3: PCA Context Vector Extraction</h2>

            <h3>5.1 Hidden State Extraction</h3>
            <p>
                Extract final layer hidden states from both positive and negative continuations:
            </p>

            <div class="code-block">
def extract_hidden_states(model, text):
    inputs = tokenizer(text, return_tensors="pt")

    with torch.no_grad():
        outputs = model(**inputs, output_hidden_states=True)
        # Get last layer hidden states
        hidden_states = outputs.hidden_states[-1]  # (1, seq_len, hidden_dim)

    return hidden_states[0].cpu().numpy()  # (seq_len, hidden_dim)
            </div>

            <h3>5.2 Difference Computation</h3>
            <p>
                Compute element-wise difference between positive and negative hidden states:
            </p>

            <div class="formula">
H_pos = [h‚ÇÅ‚Å∫, h‚ÇÇ‚Å∫, ..., h‚Çú‚Å∫]  ‚àà ‚Ñù·µóÀ£·µà
H_neg = [h‚ÇÅ‚Åª, h‚ÇÇ‚Åª, ..., h‚Çõ‚Åª]  ‚àà ‚ÑùÀ¢À£·µà

Aligned difference (take minimum length T = min(t, s)):
Œî = H_pos[:T] - H_neg[:T]  ‚àà ‚Ñù·µÄÀ£·µà

where d is the hidden dimension (e.g., 4096 for Qwen3-VL-8B)
            </div>

            <h3>5.3 Principal Component Analysis</h3>
            <p>
                Apply PCA to the difference matrix to extract the primary direction of variation:
            </p>

            <div class="formula">
PCA Decomposition:

1. Center the data:
   Œî_centered = Œî - mean(Œî, axis=0)

2. Compute covariance matrix:
   C = (1/T) Œî_centered·µÄ Œî_centered  ‚àà ‚Ñù·µàÀ£·µà

3. Eigendecomposition:
   C = V Œõ V·µÄ
   where Œõ = diag(Œª‚ÇÅ, Œª‚ÇÇ, ..., Œª‚Çê) with Œª‚ÇÅ ‚â• Œª‚ÇÇ ‚â• ... ‚â• Œª‚Çê

4. First principal component (context vector):
   v_context = V[:,0]  ‚àà ‚Ñù·µà

   Explained variance ratio: Œª‚ÇÅ / Œ£Œª·µ¢
            </div>

            <div class="code-block">
from sklearn.decomposition import PCA

def compute_pca_context_vector(positive_hidden, negative_hidden):
    # Compute PCA on (positive - negative) to extract context vector

    # Align sequences
    min_len = min(positive_hidden.shape[0], negative_hidden.shape[0])
    diff = positive_hidden[:min_len] - negative_hidden[:min_len]  # (min_len, hidden_dim)

    # Apply PCA
    pca = PCA(n_components=1)
    pca.fit(diff)

    context_vector = pca.components_[0]  # (hidden_dim,)
    explained_variance = pca.explained_variance_ratio_[0]

    print(f"Explained variance: {explained_variance:.4f}")

    return context_vector
            </div>

            <h3>5.4 Context-Augmented Generation</h3>
            <p>
                Add the context vector to decoder hidden states during generation:
            </p>

            <div class="formula">
Modified Forward Pass:

h_modified(t) = h_original(t) + Œ± √ó v_context

where:
    h_original(t) = original hidden state at time t
    v_context = PCA-extracted context vector
    Œ± = scaling factor (tested: 0.0, 0.5, 1.0, 2.0, 5.0)
            </div>

            <div class="code-block">
def generate_with_context_vector(model, prefix, context_vector, scale):
    # Generate with context vector added to hidden states

    context_tensor = torch.from_numpy(context_vector).float()

    def add_context_hook(module, input, output):
        if isinstance(output, tuple):
            hidden_states = output[0]
        else:
            hidden_states = output

        # Add scaled context vector to all positions
        hidden_states = hidden_states + scale * context_tensor

        return (hidden_states,) + output[1:] if isinstance(output, tuple) else hidden_states

    # Register hook on last decoder layer
    hook = model.model.layers[-1].register_forward_hook(add_context_hook)

    try:
        outputs = model.generate(
            tokenizer(prefix, return_tensors="pt").input_ids,
            max_new_tokens=256,
            temperature=0.9
        )
        return tokenizer.decode(outputs[0])
    finally:
        hook.remove()
            </div>

            <h3>5.5 Evaluation</h3>
            <p>
                Test multiple scale values and measure accuracy on correct answer generation:
            </p>

            <div class="formula">
For each scale Œ± ‚àà {0.0, 0.5, 1.0, 2.0, 5.0}:
    Generate N trials (N=5)
    Count correct answers
    Accuracy(Œ±) = (# correct) / N

Optimal scale: Œ±* = argmax Accuracy(Œ±)
            </div>
        </div>

        <div id="implementation" class="section">
            <h2>6. Implementation Details</h2>

            <h3>6.1 Dataset Filtering</h3>
            <div class="key-point">
                <strong>AI2D Dataset Only:</strong> We filter for images from
                <code>/mnt/hdd/llava/llava-cot-100k/extracted/ai2d/images/</code> to focus on
                diagram-based reasoning tasks.
            </div>

            <h3>6.2 Prompt Engineering</h3>
            <div class="code-block">
system_prompt = (
    "You are a helpful vision assistant analyzing images. "
    "Please provide your reasoning in &lt;think&gt;...&lt;/think&gt; tags "
    "with AT LEAST 5 numbered steps (1., 2., 3., 4., 5., ...). "
    "Each step should be a complete sentence (15-40 words). "
    "After reasoning, provide the final answer in &lt;final&gt;...&lt;/final&gt; tags."
)
            </div>

            <h3>6.3 File Organization</h3>
            <table>
                <tr>
                    <th>File</th>
                    <th>Purpose</th>
                </tr>
                <tr>
                    <td><code>main.py</code></td>
                    <td>Main entry point, dataset processing loop</td>
                </tr>
                <tr>
                    <td><code>process.py</code></td>
                    <td>Core processing: reasoning generation, KL computation</td>
                </tr>
                <tr>
                    <td><code>calculate_anchor.py</code></td>
                    <td>Anchor vector computation from KL matrix</td>
                </tr>
                <tr>
                    <td><code>contrastive_generation.py</code></td>
                    <td>Contrastive sampling and PCA context vector</td>
                </tr>
                <tr>
                    <td><code>generate_report.py</code></td>
                    <td>HTML report generation from JSON results</td>
                </tr>
                <tr>
                    <td><code>run_pca_on_existing.py</code></td>
                    <td>Post-hoc PCA testing on existing results</td>
                </tr>
            </table>

            <h3>6.4 Hardware Requirements</h3>
            <ul>
                <li>GPU: CUDA-capable (tested on 3x GPUs with 48GB each)</li>
                <li>RAM: 32GB+ recommended</li>
                <li>Storage: ~50GB for model cache + dataset</li>
            </ul>
        </div>

        <div id="code" class="section">
            <h2>7. Key Code Snippets</h2>

            <h3>7.1 Running the Full Pipeline</h3>
            <div class="code-block">
# Run with thought anchor + contrastive + PCA
python main.py \
    --dataset-split "train[:50]" \
    --max-samples 10 \
    --test-pca-context \
    --pca-num-trials 5

# Generate HTML reports
python generate_report.py
python generate_methodology.py
            </div>

            <h3>7.2 Attention Mask Creation</h3>
            <div class="code-block">
def create_attention_mask_for_suppression(
    input_ids: torch.Tensor,
    suppress_ranges: List[Tuple[int, int]],
    device: str
) -> torch.Tensor:
    # Create attention mask that prevents attending to specified ranges
    #
    # Args:
    #     input_ids: (batch_size, seq_len)
    #     suppress_ranges: List of (start, end) token ranges to suppress
    #
    # Returns:
    #     attention_mask: (batch_size, seq_len, seq_len) with -inf for suppressed positions

    seq_len = input_ids.shape[1]

    # Start with causal mask (lower triangular)
    causal_mask = torch.triu(
        torch.full((seq_len, seq_len), float('-inf')),
        diagonal=1
    ).to(device)

    # Add suppressions
    for start, end in suppress_ranges:
        causal_mask[:, start:end] = float('-inf')

    return causal_mask.unsqueeze(0)  # (1, seq_len, seq_len)
            </div>

            <h3>7.3 Answer Extraction</h3>
            <div class="code-block">
def extract_final_answer(text: str) -> Optional[str]:
    # Extract final answer from &lt;final&gt; tags or patterns

    # Try &lt;final&gt;...&lt;/final&gt;
    if "&lt;final&gt;" in text and "&lt;/final&gt;" in text:
        start = text.find("&lt;final&gt;") + len("&lt;final&gt;")
        end = text.find("&lt;/final&gt;")
        return text[start:end].strip()

    # Try patterns like "Final Answer: X" or "The answer is X"
    patterns = [
        r'(?:[Ff]inal [Aa]nswer|[Tt]he (?:correct |final )?answer is|[Aa]nswer):?\s*(.+)',
    ]

    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            answer = match.group(1).strip()
            # Remove markdown bold
            answer = re.sub(r'\*\*([^\*]+)\*\*', r'\1', answer)
            # Remove trailing punctuation
            answer = re.sub(r'[.,!?]+$', '', answer)
            return answer.strip()

    # Fallback: last line
    return text.strip().split("\n")[-1].strip()
            </div>
        </div>

        <div class="section">
            <h2>8. References</h2>
            <ul>
                <li>Thought Anchors Paper: Method 3 - Attention Masking for counterfactual analysis</li>
                <li>Qwen3-VL: <a href="https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct">Hugging Face Model Card</a></li>
                <li>Principal Component Analysis: Jolliffe, I. T. (2002). Principal Component Analysis, Second Edition</li>
                <li>KL Divergence: Kullback, S.; Leibler, R. A. (1951). "On Information and Sufficiency"</li>
            </ul>
        </div>

        <div class="section" style="margin-top: 60px; padding-top: 20px; border-top: 2px solid #ddd; text-align: center; color: #666;">
            <p>Generated on 2025-11-20 | Thought Anchor & Contrastive Generation Project</p>
        </div>
    </div>
</body>
</html>
